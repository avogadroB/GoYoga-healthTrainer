{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc13e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install playsound\n",
    "#!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292160eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time \n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import pyautogui\n",
    "from time import time\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2664b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"1 प्रणामासन\"\n",
    "tts1=gTTS(text=text1, lang='hi')\n",
    "tts1.save('pose_1.mp3')\n",
    "\n",
    "text12=\"12 प्रणामासन\"\n",
    "tts12=gTTS(text=text12, lang='hi')\n",
    "tts12.save('pose_12.mp3')\n",
    "\n",
    "text2=\"2 हस्त उत्तानासन\"\n",
    "tts2=gTTS(text=text2, lang='hi')\n",
    "tts2.save('pose_2.mp3')\n",
    "\n",
    "text11=\"11 हस्त उत्तानासन\"\n",
    "tts11=gTTS(text=text11, lang='hi')\n",
    "tts11.save('pose_11.mp3')\n",
    "\n",
    "text3=\"3 पाद हस्तासन\"\n",
    "tts3=gTTS(text=text3, lang='hi')\n",
    "tts3.save('pose_3.mp3')\n",
    "\n",
    "text10=\"10 पाद हस्तासन\"\n",
    "tts10=gTTS(text=text10, lang='hi')\n",
    "tts10.save('pose_10.mp3')\n",
    "\n",
    "text4=\"4 अश्व संचलानासन\"\n",
    "tts4=gTTS(text=text4, lang='hi')\n",
    "tts4.save('pose_4.mp3')\n",
    "\n",
    "text9=\"9 अश्व संचलानासन\"\n",
    "tts9=gTTS(text=text9, lang='hi')\n",
    "tts9.save('pose_9.mp3')\n",
    "\n",
    "text5=\"5 दंडासन\"\n",
    "tts5=gTTS(text=text5, lang='hi')\n",
    "tts5.save('pose_5.mp3')\n",
    "\n",
    "text6=\"6 अष्टांग नमस्कार\"\n",
    "tts6=gTTS(text=text6, lang='hi')\n",
    "tts6.save('pose_6.mp3')\n",
    "\n",
    "text7=\"7 भुजंगासन\"\n",
    "tts7=gTTS(text=text7, lang='hi')\n",
    "tts7.save('pose_7.mp3')\n",
    "\n",
    "text8=\"8 अधो मुख शवासन\"\n",
    "tts8=gTTS(text=text8, lang='hi')\n",
    "tts8.save('pose_8.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf3af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound(\".\\pose_12.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3186b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Setting up the Pose function.\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "# Initializing mediapipe drawing class, useful for annotation.\n",
    "mp_drawing = mp.solutions.drawing_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14364abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    \n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "    \n",
    "    # Return the calculated angle.\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53d1e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose,draw=False, display=True):\n",
    "    \n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "    \n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "    \n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "    \n",
    "        # Draw Pose landmarks on the output image.\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),thickness=3, circle_radius=3), connection_drawing_spec=mp_drawing.DrawingSpec(color=(49,125,237),thickness=2, circle_radius=2))\n",
    "        \n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            \n",
    "            # Append the landmark into the list.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "    \n",
    "    # Check if the original input image and the resultant image are specified to be displayed.\n",
    "    if display:\n",
    "    \n",
    "        # Display the original input image and the resultant image.\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        \n",
    "        # Also Plot the Pose landmarks in 3D.\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "    # Otherwise\n",
    "    else:\n",
    "        \n",
    "        # Return the output image and the found landmarks.\n",
    "        return output_image, landmarks, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6924ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Pose function for video.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Create named window for resizing purposes\n",
    "cv2.namedWindow('Pose Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "\n",
    "# Initialize the VideoCapture object to read from a video stored in the disk.\n",
    "#video = cv2.VideoCapture('media/running.mp4')\n",
    "\n",
    "# Set video camera size\n",
    "video.set(3,1280)\n",
    "video.set(4,960)\n",
    "\n",
    "# Initialize a variable to store the time of the previous frame.\n",
    "time1 = 0\n",
    "\n",
    "# Iterate until the video is accessed successfully.\n",
    "while video.isOpened():\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = video.read()\n",
    "    \n",
    "    # Check if frame is not read properly.\n",
    "    if not ok:\n",
    "        \n",
    "        # Break the loop.\n",
    "        break\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Get the width and height of the frame\n",
    "    frame_height, frame_width, _ =  frame.shape\n",
    "    \n",
    "    # Resize the frame while keeping the aspect ratio.\n",
    "    frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "    \n",
    "    # Perform Pose landmark detection.\n",
    "    frame, _ = detectPose(frame, pose_video, display=False)\n",
    "    \n",
    "    # Set the time for this frame to the current time.\n",
    "    time2 = time()\n",
    "    \n",
    "    # Check if the difference between the previous and this frame time > 0 to avoid division by zero.\n",
    "    if (time2 - time1) > 0:\n",
    "    \n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = 1.0 / (time2 - time1)\n",
    "        \n",
    "        # Write the calculated number of frames per second on the frame. \n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "    \n",
    "    # Update the previous frame time to this frame time.\n",
    "    # As this frame will become previous frame in next iteration.\n",
    "    time1 = time2\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "    \n",
    "    # Wait until a key is pressed.\n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Check if 'ESC' is pressed.\n",
    "    if(k == 27):\n",
    "        \n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object.\n",
    "video.release()\n",
    "\n",
    "# Close the windows.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f2a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLeftRight(image, results, draw=False, display=False):\n",
    "    \n",
    "    # Declare a variable to store the horizontal position (left, center, right) of the person.\n",
    "    horizontal_position = None\n",
    "    \n",
    "    # Get the height and width of the image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Create a copy of the input image to write the horizontal position on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    left_x = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].x * width)\n",
    "    right_x = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].x * width)\n",
    "\n",
    "    left_y = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].y * height)\n",
    "    right_y = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].y * height)\n",
    "    \n",
    "    # Check if the person is at left that is when both shoulder landmarks x-corrdinates\n",
    "    # are less than or equal to the x-corrdinate of the center of the image.\n",
    "    if ((left_x <= width//8 and left_y<=height//8) or (right_x <=width//8 and right_y<=height//8)):\n",
    "        \n",
    "        # Set the person's position to left.\n",
    "        horizontal_position = 'Left button'\n",
    "\n",
    "    # Check if the person is at right that is when both shoulder landmarks x-corrdinates\n",
    "    # are greater than or equal to the x-corrdinate of the center of the image.\n",
    "    elif ((right_x >= 7*width//8 and right_y<=height//8) or (left_x>=7*width//8 and left_y<=height//8)):\n",
    "        \n",
    "        # Set the person's position to right.\n",
    "        horizontal_position = 'Right button'\n",
    "        \n",
    "    # Check if the person's horizontal position and a line at the center of the image is specified to be drawn.\n",
    "    if draw:\n",
    "\n",
    "        # Write the horizontal position of the person on the image. \n",
    "        cv2.putText(output_image, horizontal_position, (5, height - 10), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 3)\n",
    "        \n",
    "        # Draw a line at the center of the image.\n",
    "        cv2.line(output_image, (width//8, 0), (width//8, height//8), (255, 255, 255), 2)\n",
    "        cv2.line(output_image, (0, height//8), (width//8, height//8), (255, 255, 255), 2)\n",
    "        cv2.line(output_image, (7*width//8, 0), (7*width//8, height//8), (255, 255, 255), 2)        \n",
    "        cv2.line(output_image, (7*width//8, height//8), (width,height//8), (255, 255, 255), 2)\n",
    "\n",
    "        cv2.rectangle(output_image, (7*width//8, 0) , (width, height//8),  (66, 148, 45), -1)\n",
    "        cv2.putText(output_image, \"NEXT\", (7*width//8 + 10, height//16), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "    # Check if the output image is specified to be displayed.\n",
    "    if display:\n",
    "\n",
    "        # Display the output image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "    \n",
    "        # Return the output image and the person's horizontal position.\n",
    "        return output_image, horizontal_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7469c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "\n",
    "    # Get the required landmarks coordinates.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    \n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "    \n",
    "    # Return the calculated angle.\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e69397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPose(landmarks, output_image, display=False):\n",
    "    \n",
    "    # Initialize the label of the pose. It is not known at this stage.\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Specify the color (Red) with which the label will be written on the image.\n",
    "    color = (0, 0, 255)\n",
    "    \n",
    "    # Calculate the required angles.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Get the angle between the right shoulder, elbow and wrist points. \n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n",
    "    \n",
    "    # Get the angle between the right hip, shoulder and elbow points. \n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
    "\n",
    "    # Get the angle between the right hip, knee and ankle points \n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    \n",
    "    #right index, right wrist, right elbow\n",
    "    right_wrist_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value])\n",
    "\n",
    "    #right knee, hip, shoulder\n",
    "    right_hip_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])\n",
    "    #pose 1\n",
    "    if right_elbow_angle>50 and right_elbow_angle<90 and right_shoulder_angle>20 and right_shoulder_angle <50 and right_wrist_angle>120 and right_wrist_angle<160:\n",
    "        label='1, 12. Pranamasana'\n",
    "        \n",
    "    #pose 2\n",
    "    if right_elbow_angle>140 and right_elbow_angle< 170 and right_shoulder_angle>170 and right_shoulder_angle<210 and right_wrist_angle>130 and right_wrist_angle<170 :\n",
    "        label='2, 11. Hasta Uttanasana'\n",
    "    \n",
    "    #pose 3\n",
    "    if right_hip_angle>280 and right_elbow_angle>160 and right_elbow_angle< 210: \n",
    "        label='3, 10. Pada Hastasana'\n",
    "    \n",
    "    #pose 4\n",
    "    if (right_elbow_angle>160 and right_elbow_angle<190 and right_shoulder_angle>30 and right_shoulder_angle<60 and right_hip_angle>160 and right_hip_angle<190 and right_knee_angle>210) or (right_elbow_angle>160 and right_elbow_angle<190 and right_shoulder_angle>30 and right_shoulder_angle<60 and right_hip_angle>160 and right_hip_angle<190 and left_knee_angle>210):\n",
    "        label='4, 9. Ashwa Sanchalanasana'\n",
    "    \n",
    "    #pose 5\n",
    "    if right_elbow_angle>160 and right_elbow_angle< 190 and  right_shoulder_angle>50 and  right_shoulder_angle<80 and right_knee_angle>160 and right_knee_angle<190 and right_wrist_angle>80 and right_wrist_angle<120 and right_hip_angle>160 and right_hip_angle<190:\n",
    "        label='5. Dandasana'\n",
    "        \n",
    "    #pose 6\n",
    "    if right_elbow_angle>30 and right_elbow_angle<60 and right_shoulder_angle>320 and right_knee_angle>190 and right_knee_angle<240 and right_hip_angle>210 and right_hip_angle<250:\n",
    "        label= '6. Ashtanga Namaskara'\n",
    "        \n",
    "    #pose 7\n",
    "    if right_elbow_angle>150 and right_elbow_angle<185 and right_shoulder_angle>10 and right_shoulder_angle<50 and right_knee_angle>175 and right_knee_angle< 200 and right_hip_angle>100 and right_hip_angle<140:\n",
    "        label= '7. Bhujang Asana'\n",
    "        \n",
    "    #pose 8\n",
    "    if right_elbow_angle>160 and right_elbow_angle<190 and right_shoulder_angle>150 and right_shoulder_angle<190 and right_knee_angle>150 and right_knee_angle< 190  and right_hip_angle>250 and right_hip_angle<310:\n",
    "        label= '8. Adho mukha savasana'\n",
    "        \n",
    "    #pose 9 is the same as pose 4\n",
    "    #pose 10 is the same as pose 3\n",
    "    #pose 11 is the same as pose 2\n",
    "    #pose 12 is the same as pose 1\n",
    "    # Check if the pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        \n",
    "        # Update the color (to green) with which the label will be written on the image.\n",
    "        color = (0, 255, 0)  \n",
    "    \n",
    "    # Write the label on the output image. \n",
    "    cv2.putText(output_image, label, (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "    \n",
    "    # Check if the resultant image is specified to be displayed.\n",
    "    if display:\n",
    "    \n",
    "        # Display the resultant image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Return the output image and the classified label.\n",
    "        return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e3a7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Pose function for video.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "# Initialize a resizable window.\n",
    "cv2.namedWindow('Pose Classification', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly.\n",
    "    if not ok:\n",
    "        \n",
    "        # Continue to the next iteration to read the next frame and ignore the empty camera frame.\n",
    "        continue\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Get the width and height of the frame\n",
    "    frame_height, frame_width, _ =  frame.shape\n",
    "    \n",
    "    # Resize the frame while keeping the aspect ratio.\n",
    "    frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "    \n",
    "    # Perform Pose landmark detection.\n",
    "    frame, landmarks, results = detectPose(frame, pose_video, display=False, draw=True)\n",
    "    if landmarks:\n",
    "        \n",
    "        # Perform the Pose Classification.\n",
    "        frame= classifyPose(landmarks, frame, display=False)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "            \n",
    "        # Check the horizontal position of the person in the frame.\n",
    "        frame, pressbutton = checkLeftRight(frame, results, draw=True)\n",
    "        if(pressbutton=='Left button'):\n",
    "            pyautogui.press('left')\n",
    "        if(pressbutton=='Right button'):\n",
    "            pyautogui.press('right')\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow('Pose Classification', frame)\n",
    "    \n",
    "    # Wait until a key is pressed.\n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Check if 'ESC' is pressed.\n",
    "    if(k == 27):\n",
    "        \n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1c92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdafeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a0bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
